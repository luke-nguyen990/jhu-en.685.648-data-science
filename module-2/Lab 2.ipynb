{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fundamentals-of-data-science/course-materials/blob/master/labs/Lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zi1DjOpGw0a9"
   },
   "source": [
    "# Module 2 Lab - Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuTuPF2Aw0a_"
   },
   "source": [
    "## General Instructions\n",
    "\n",
    "In this course, Labs are the chance to applying concepts and methods discussed in the module.\n",
    "They are a low stakes (pass/fail) opportunity for you to try your hand at *doing*.\n",
    "Please make sure you follow the general Lab instructions, described in the Syllabus.\n",
    "The summary is:\n",
    "\n",
    "* Discussions should start as students work through the material, first Wednesday at the start of the new Module week. \n",
    "* Labs are due by **Sunday**.\n",
    "* Lab solutions are released Monday.  \n",
    "* Post Self Evaluation and Lab to Lab Group on Blackboard and Lab to Module on Blackboard on **Monday**.\n",
    "\n",
    "The last part is important because the Problem Sets will require you to perform the same or similar tasks without guidance.\n",
    "Problem Sets are your opportunity to demonstrate that you understand how to apply the concepts and methods discussed in the relevant Modules and Labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Instructions\n",
    "\n",
    "1.  For Blackboard submissions, if there are no accompanying files, you should submit *only* your notebook and it should be named using *only* your JHED id: fsmith79.ipynb for example if your JHED id were \"fsmith79\". If the assignment requires additional files, you should name the *folder/directory* your JHED id and put all items in that folder/directory, ZIP it up (only ZIP...no other compression), and submit it to Blackboard.\n",
    "\n",
    "    * do **not** use absolute paths in your notebooks. All resources should located in the same directory as the rest of your assignments.\n",
    "    * the directory **must** be named your JHED id and **only** your JHED id.\n",
    "    * do **not** return files provided by us (data files, .py files)\n",
    "\n",
    "\n",
    "2. Data Science is as much about what you write (communicating) as the code you execute (researching). In many places, you will be required to execute code and discuss both the purpose and the result. Additionally, Data Science is about reproducibility and transparency. This includes good communication with your team and possibly with yourself. Therefore, you must show **all** work.\n",
    "\n",
    "3. Avail yourself of the Markdown/Codecell nature of the notebook. If you don't know about Markdown, look it up. Your notebooks should not look like ransom notes. Don't make everything bold. Clearly indicate what question you are answering.\n",
    "\n",
    "4. Submit a cleanly executed notebook. The first code cell should say `In [1]` and each successive code cell should increase by 1 throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aoUSHSmHw0bC"
   },
   "source": [
    "## Manipulating and Interpreting Probability\n",
    "\n",
    "Given the following *joint probability distribution*, $P(A,B)$, for $A$ and $B$,\n",
    "\n",
    "```\n",
    "|    | a1   | a2   |\n",
    "|----|------|------|\n",
    "| b1 | 0.37 | 0.16 |\n",
    "| b2 | 0.23 | 0.24 |\n",
    "```\n",
    "\n",
    "Answer the following questions.\n",
    "\n",
    "**1\\. What is $P(A=a2, B=b2)$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLkEU6Gww0bF"
   },
   "source": [
    "**$P(A=a2, B=b2)$ = 0.24**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBpDJLMBw0bH"
   },
   "source": [
    "**2\\. If I observe events from this probability distribution, what is the probability of seeing (a1, b1) then (a2, b2)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNfPdLVaw0bJ"
   },
   "source": [
    "*P(A = a1, B = b1) * P(A = a2, B = b2) = 0.37 * 0.24 = 0.0888*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TdY20dH3w0bK"
   },
   "source": [
    "**3\\. Calculate the marginal probability distribution, $P(A)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSEK8ToJw0bQ"
   },
   "source": [
    "```\n",
    "| a1   | a2   |\n",
    "|------|------|\n",
    "| 0.60 | 0.40 |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHmrDBRew0bS"
   },
   "source": [
    "**4\\. Calculate the marginal probability distribution, $P(B)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2JDyyBiw0bU"
   },
   "source": [
    "```\n",
    "|----|------|\n",
    "| b1 | 0.53 |\n",
    "| b2 | 0.47 |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqghXUoZw0bV"
   },
   "source": [
    "**5\\. Calculate the conditional probability distribution, $P(A|B)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wnh_1qdyw0bX"
   },
   "source": [
    "*P(A = a1 | B = b1) = 0.37/0.53 = 0.6981*<br>\n",
    "*P(A = a2 | B = b1) = 0.16/0.53 = 0.3019*<br>\n",
    "*P(A = a1 | B = b2) = 0.23/0.47 = 0.4894*<br>\n",
    "*P(A = a2 | B = b2) = 0.24/0.47 = 0.5106*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgKCDL4-w0bY"
   },
   "source": [
    "**6\\. Calculate the conditional probability distribution, $P(B|A)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lD3r4Xhgw0ba"
   },
   "source": [
    "*P(B = b1 | A = a1) = 0.37/0.60 = 0.6167* <br>\n",
    "*P(B = b2 | A = a1) = 0.37/0.60 = 0.3833* <br>\n",
    "*P(B = b1 | A = a2) = 0.16/0.40 = 0.4000* <br>\n",
    "*P(B = b2 | A = a2) = 0.24/0.40 = 0.6000*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdjtfwHaw0bc"
   },
   "source": [
    "**7\\. Does $P(A|B) = P(B|A)$? What do we call the belief that these are always equal?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkH-Un_Cw0bd"
   },
   "source": [
    "*From this joint probability, P(A|B) != P(B|A)* <br>\n",
    "We call the belief that these are always equal **Inverse Probability Fallacy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SglgfKUw0be"
   },
   "source": [
    "**8\\. Does $P(A) = P(A|B)$? What does that mean about the independence of $A$ and $B$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxMlSSIEw0bf"
   },
   "source": [
    "*From this joint probability, P(A) != P(A|B)* <br>\n",
    "This means that A and B are not independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p67gfq-Jw0bg"
   },
   "source": [
    "**9\\. Using $P(A)$, $P(B|A)$, $P(B)$ from above, calculate,**\n",
    "\n",
    "$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n",
    "\n",
    "Does it match your previous calculation for $P(A|B)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUcxPvZFw0bh"
   },
   "source": [
    "Let's consider A = a2, B = b2 as follows <br>\n",
    "$P(A = a2|B = b2) = \\frac{P(B = b2|A = a2)P(A = a2)}{P(B = b2)}$ <br>\n",
    "\n",
    "$P(A = a2|B = b2) = \\frac{0.6000 * 0.4000}{0.4700} = 0.5106$ <br>\n",
    "\n",
    "**Yes, it matches**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EeMKnxIw0bi"
   },
   "source": [
    "**10\\. If we let A = H (some condition, characteristic, hypothesis) and B = D (some data, evidence, a test result), then how do we interpret each of the following: $P(H)$, $P(D)$, $P(H|D)$, $P(D|H)$, $P(H, D)$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpeGvo4Kw0bm"
   },
   "source": [
    "**P(H)** = prior probability - probability that the given condition will happen for the whole sample space. <br>\n",
    "**P(D)** = normalizer - probability that a data is a test data. <br>\n",
    "**P(H|D)** = posterior probability - probability the given condition will happen for the test data. <br>\n",
    "**P(D|H)** = likelihood - probability that when the given condition happens, it is in the test data. <br>\n",
    "**P(H, D)** = probability that the given condition happens and it is the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EnYagt27w0bo"
   },
   "source": [
    "## Bayes Rule\n",
    "\n",
    "Bayes Rule will be an important part of our toolset in the weeks to come, especially in terms of Bayesian Inference. Work through the following problems in Bayes Rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oL8kmom4w0bp"
   },
   "source": [
    "### Problem 1 (Regular)\n",
    "\n",
    "You might be interested in the relationship between alcoholism and liver disease, in which case âbeing an alcoholicâ (or not) is a test (evidence for) for liver disease (or not).\n",
    "\n",
    "Let `D` be the presence or absence of liver disease (`d` they have it; `~d`, \"not d\", they don't). Past data tells you that 10% of patients entering your clinic have liver disease. Let `A` be alcoholic (`a`) or not alcoholic (`~a`). 5% of the clinicâs patients are alcoholics.\n",
    "\n",
    "You know that among those patients diagnosed with liver disease, 7% are alcoholics and among those without liver disease, 95.2% are non-alcoholics.\n",
    "\n",
    "c2. From the above word problem, what values of Bayes Rule do you have? Which ones are missing?\n",
    "3. Calculate the missing values.\n",
    "4. Calculate the posterior probability *distributions* using Bayes Rule.\n",
    "5. Describe what each individual posterior probability means *in words*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qL5KnyVsw0bq"
   },
   "source": [
    "1. Bayes rule for this problem: <br>\n",
    "$P(D|A) = \\frac{P(A|D)P(D)}{P(A)}$ <br>\n",
    "\n",
    "2. What we have: <br>\n",
    "$P(A = a|D = d) = 0.070$ <br>\n",
    "$P(A = \\~a|D = \\~d) = 0.952$ <br>\n",
    "$P(D = d) = 0.100$ <br>\n",
    "$P(A = a) = 0.050$ <br>\n",
    "\n",
    "3. Calculate missing values: <br>\n",
    "$P(A = \\~a|D = d) = 1.000 - 0.070 = 0.930$ <br>\n",
    "$P(A = a|D = \\~d) = 1.000 - 0.952 = 0.048$ <br>\n",
    "$P(D = \\~d) = 1.000 - 0.100 = 0.900$ <br>\n",
    "$P(A = \\~a) = 1.000 - 0.050 = 0.950$ <br>\n",
    "\n",
    "4. Calculate the posterior probability *distributions* using Bayes Rule: <br>\n",
    "$P(d | a) = \\frac{P(a | d)P(d)}{P(a)} = \\frac{0.070 * 0.100}{0.050} = 0.140$<br>\n",
    "$P(\\~d | a) = \\frac{P(a | \\~d)P(\\~d)}{P(a)} = \\frac{0.048 * 0.900}{0.050} = 0.864$<br>\n",
    "$P(d | \\~a) = \\frac{P(\\~a | d)P(d)}{P(\\~a)} = \\frac{0.930 * 0.100}{0.950} = 0.098$<br>\n",
    "$P(\\~d | \\~a) = \\frac{P(\\~a | \\~d)P(\\~d)}{P(\\~a)} = \\frac{0.952 * 0.900}{0.950} = 0.902$<br>\n",
    "\n",
    "5. In words: <br>\n",
    "Given that a patient is alcoholic, then the patient has 14% chance of having liver disease. <br>\n",
    "Given that a patient is alcoholic, then the patient has 86% chance of not having liver disease. <br>\n",
    "Given that a patient is non-alcoholic, then the patient has 9.8% chance of having liver disease. <br>\n",
    "Given that a patient is non-alcoholic, then the patient has 90.2% chance of not having liver disease. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wf1S_QSIw0br"
   },
   "source": [
    "### Problem 2 (Harder)\n",
    "\n",
    "In a particular pain clinic, 10% of patients are prescribed narcotic pain killers. Overall, five percent of the clinicâs patients are addicted to narcotics (including pain killers and illegal substances). Out of all the people prescribed pain pills, 8% are addicts. What is the relationship between addiction and pain pill prescriptions?\n",
    "\n",
    "1. What is Bayes Rule for this problem? (write it out symbolically)\n",
    "2. From the above word problem, what values of Bayes Rule do you have? Which ones are missing?\n",
    "3. Calculate the missing values.\n",
    "4. Calculate the posterior probability *distributions* using Bayes Rule.\n",
    "5. Describe what each individual posterior probability means *in words*.\n",
    "\n",
    "(Note: this problem is structured slightly differently than usual. You will need to use Total Probability and the Axioms of Probability as well as solving simultaneous equations to get the answer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igoRDGJww0bs"
   },
   "source": [
    "Let $A$ be the addictive status, with $a$ = addictive, $\\~a$ = not-addictive. <br>\n",
    "Let $K$ be the prescribed narcotic pain killers, with $k$ = prescribed, $\\~k$ = not-prescribed. <br>\n",
    "\n",
    "1. Bayes rule for this problem: <br>\n",
    "$P(K|A) = \\frac{P(A|K)P(K)}{P(A)}$ <br>\n",
    "\n",
    "2. What we have: <br>\n",
    "$P(k) = 0.1$ <br>\n",
    "$P(a | k) = 0.08$ <br>\n",
    "$P(a) = 0.05$ <br>\n",
    "\n",
    "3. Calculate missing values: <br>\n",
    "$P(\\~k) = 1 - 0.1 = 0.9$ <br>\n",
    "$P(\\~a) = 1 - 0.05 = 0.95$ <br>\n",
    "$P(\\~a | k) = 1 - 0.08 = 0.92$ <br>\n",
    "$P(a | \\~k) = (0.05 * 0.9) / 0.9 = 0.05$ <br>\n",
    "$P(\\~a | \\~k) = 1 - 0.05 = 0.95$ <br>\n",
    "\n",
    "4. Calculate the posterior probability *distributions* using Bayes Rule: <br>\n",
    "$P(k | a) = \\frac{P(a | k)P(k)}{P(a)} = \\frac{0.08 * 0.1}{0.05} = 0.16$<br>\n",
    "$P(\\~k | a) = \\frac{P(a | \\~k)P(\\~k)}{P(a)} = \\frac{0.05 * 0.9}{0.05} = 0.9$<br>\n",
    "$P(k | \\~a) = \\frac{P(\\~a | k)P(k)}{P(\\~a)} = \\frac{0.92 * 0.1}{0.95} = 0.0968$<br>\n",
    "$P(\\~k | \\~a) = \\frac{P(\\~a | \\~k)P(\\~k)}{P(\\~a)} = \\frac{0.95 * 0.9}{0.95} = 0.9$<br>\n",
    "\n",
    "5. In words: <br>\n",
    "Given that a patient is addictive, then the patient has 16% chance of being prescribed with pain killer. <br>\n",
    "Given that a patient is addictive, then the patient has 90% chance of not being prescribed with pain killer. <br>\n",
    "Given that a patient is non-addictive, then the patient has 9.7% chance of not being prescribed with pain killer. <br>\n",
    "Given that a patient is non-addictive, then the patient has 90.2% chance of not being prescribed with pain killer. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you worked through the Titanic case study. This is a continuation of that analysis. *Feel free to copy code blocks from the case study as you see fit*\n",
    "\n",
    "We start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"https://raw.githubusercontent.com/fundamentals-of-data-science/datasets/master/titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probabilities\n",
    "\n",
    "1. Calculate $P(survived|parch)$\n",
    "\n",
    "(Remember...every \"calculation\" includes discuss/code/discuss. In this case, describe what the conditional probability is, what you expect to see, calculate it, and then discuss the results relative to your hypothesized values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(survived|parch)\n",
      "survived       0.0       1.0\n",
      "parch                       \n",
      "0.0       0.664671  0.335329\n",
      "1.0       0.411765  0.588235\n",
      "2.0       0.495575  0.504425\n",
      "3.0       0.375000  0.625000\n",
      "4.0       0.833333  0.166667\n",
      "5.0       0.833333  0.166667\n",
      "6.0       1.000000  0.000000\n",
      "9.0       1.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "from pandas.core.algorithms import value_counts\n",
    "from pandas.core.reshape.concat import concat\n",
    "\n",
    "def summarize_category(series):\n",
    "    res_regu = value_counts(series)\n",
    "    res_norm = value_counts(series, normalize=True)\n",
    "    result = concat([res_regu, res_norm], axis=1, keys=['Count', 'Frequency'])\n",
    "    result = result.sort_index()\n",
    "    return result\n",
    "\n",
    "# print(titanic[\"parch\"])\n",
    "# print(titanic)\n",
    "# titanic.info()\n",
    "# passengers = len(titanic)\n",
    "\n",
    "pd.DataFrame(titanic[\"parch\"].describe())\n",
    "parch_counts = summarize_category(titanic[\"parch\"])\n",
    "parch_counts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conditional_probability(df, target, givens, cell=\"index\"):\n",
    "    \"\"\"\n",
    "    calculates a simple conditional probability (only one target variable) based off of:\n",
    "    https://stackoverflow.com/questions/54040923/change-order-of-pandas-multiindex\n",
    "    P(target|givens...)\n",
    "    df: the DataFrame to use for the calculation\n",
    "    target: the string name of the target variable\n",
    "    givens: a string or List of strings that represent the \"givens\"\n",
    "    cell: a column that is neither target nor givens to \"count\". Should be a column withouThe default assumes you have added a column: df[\"index\"] = df.index to your DataFrame.\"\"\"\n",
    "    if isinstance(givens, str):\n",
    "        givens = [givens]\n",
    "    print(f\"P({target}|{', '.join(givens)})\")\n",
    "    columns = [target] + givens\n",
    "    # handling multiple targets would require a more sophisticated join.\n",
    "    result = (df.groupby(columns).count() / df.groupby(givens).count())[cell]\n",
    "    # this makes sure the target is always the column\n",
    "    result = result.reorder_levels(givens + [target]).sort_index()\n",
    "    # this flattens the hiearchical index and should fill in missing values.\n",
    "    result = result.unstack(fill_value=0.0)\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "print(conditional_probability(titanic, \"survived\", [\"parch\"], \"name\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate $P(survived|fare)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(survived|ticket)\n",
      "survived          0.0       1.0\n",
      "ticket                         \n",
      "110152       0.000000  1.000000\n",
      "110413       0.333333  0.666667\n",
      "110465       1.000000  0.000000\n",
      "110469       1.000000  0.000000\n",
      "110489       1.000000  0.000000\n",
      "...               ...       ...\n",
      "W./C. 6608   1.000000  0.000000\n",
      "W./C. 6609   1.000000  0.000000\n",
      "W.E.P. 5734  0.500000  0.500000\n",
      "W/C 14208    1.000000  0.000000\n",
      "WE/P 5735    0.500000  0.500000\n",
      "\n",
      "[929 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(titanic[\"ticket\"].describe())\n",
    "print(conditional_probability(titanic, \"survived\", [\"ticket\"], \"name\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate the Naive Bayes Classifier for $P(survived|pclass, sex, decade, parch, sibsp)$ and make 5 predictions.\n",
    "\n",
    "(Remember...discuss/code/discuss. This is especially true for the predictions...when you make up each passenger, do you expect them to survive or perish?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/en685648/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0724418, 0.9275582]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "titanic[\"decade\"] = (titanic[\"age\"] // 10) * 10\n",
    "\n",
    "clf = CategoricalNB()\n",
    "encoder = OrdinalEncoder()\n",
    "with_age = titanic[titanic[\"age\"].notnull()]\n",
    "\n",
    "\n",
    "encoder.fit(with_age[[\"pclass\", \"sex\", \"decade\", \"parch\", \"sibsp\"]])\n",
    "clf.fit(encoder.transform(with_age[[\"pclass\", \"sex\", \"decade\", \"parch\", \"sibsp\"]]), with_age[\"survived\"])\n",
    "encoder.categories_\n",
    "\n",
    "\n",
    "# Prediction 1: \n",
    "# classify whether a first class, female, 20 years old, 0 parch, 0 sliblings will survive\n",
    "clf.predict(encoder.transform([(1, 'female', 20, 0, 0)]))\n",
    "clf.predict_proba(encoder.transform([(1, 'female', 20, 0, 0)]))\n",
    "# conclusion, she survives with a raw probability of survival = 0.81251143\n",
    "\n",
    "# Prediction 2: \n",
    "# classify whether a first class, male, 40 years old, 0 parch, 0 sliblings will survive\n",
    "clf.predict(encoder.transform([(1, 'male', 40, 0, 0)]))\n",
    "clf.predict_proba(encoder.transform([(1, 'male', 40, 0, 0)]))\n",
    "# conclusion, he perishes with raw probability of survival = 0.28578456\n",
    "\n",
    "# Prediction 3: \n",
    "# classify whether a first class, male, 40 years old, 0 parch, 0 sliblings will survive\n",
    "clf.predict(encoder.transform([(2, 'male', 40, 0, 0)]))\n",
    "clf.predict_proba(encoder.transform([(2, 'male', 40, 0, 0)]))\n",
    "# conclusion, he perishes with raw probability of survival = 0.15285209\n",
    "\n",
    "# Prediction 4: \n",
    "# classify whether a first class, male, 10 years old, 1 parch, 0 sliblings will survive\n",
    "clf.predict(encoder.transform([(1, 'male', 10, 1, 0)]))\n",
    "clf.predict_proba(encoder.transform([(1, 'male', 10, 1, 0)]))\n",
    "# conclusion, he survives with raw probability of survival = 0.52385029\n",
    "\n",
    "# Prediction 5: \n",
    "# classify whether a first class, male, 10 years old, 1 parch, 0 sliblings will survive\n",
    "clf.predict(encoder.transform([(1, 'female', 10, 1, 0)]))\n",
    "clf.predict_proba(encoder.transform([(1, 'female', 10, 1, 0)]))\n",
    "# conclusion, she survives with raw probability of survival = 0.9275582\n",
    "\n",
    "\n",
    "# survived_pclass_and_sex = conditional_probability(titanic, \"survived\", [\"pclass\", \"sex\", \"decade\", \"parch\", \"sibsp\"], \"name\")\n",
    "# survived_pclass_and_sex"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Lab 2.ipynb",
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python (en685648)",
   "language": "python",
   "name": "en685648"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
